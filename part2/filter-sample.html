<html>

<body>
    <h3>Example Video Filter</h3>
    <a href="https://github.com/gpujs/gpu.js/issues/229#issuecomment-361093612">See original comment on GitHub</a>

    <div id="fps"></div>
    <script src="js/gpuv0.js?nocache"></script>
    <script src="js/decls.js?nocache"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            // Pipeline options
            var height = 150;
            var width = 200;

            // Video element for capturing the video
            var video = document.createElement('video');
            document.body.appendChild(video);
            video.setAttribute('playsinline', '');
            video.setAttribute('autoplay', '');
            video.setAttribute('muted', '');
            video.style.height = height;
            video.style.width = width;

            // We need this 2d context to extract image data from the video element
            var blitCanvasContext = document.createElement("canvas").getContext("2d");

            var gpu = new GPU();

            // We need something to convert the linear rgba array to a more sensible format
            var importTexture = gpu.createKernel(function (input, width, height) {
                return input[((height - this.thread.y) * width * 4) + (this.thread.x * 4) + this.thread.z] / 255.0
            })
                .outputToTexture(true)
                .dimensions([width, height, 4]);

            // All channel filter
            var filterTexture = gpu.createKernel(function (input) {
                // Remove all greens!
                if (this.thread.z === 1) return 0;
                // Half the blues
                if (this.thread.z === 2) return input[this.thread.z][this.thread.y][this.thread.x] / 2.0;
                // Unaffected
                return input[this.thread.z][this.thread.y][this.thread.x];
            })
                .outputToTexture(true)
                .dimensions([width, height, 4]);

            var renderTexture = gpu.createKernel(function (input) {
                var r = input[0][this.thread.y][this.thread.x];
                var g = input[1][this.thread.y][this.thread.x];
                var b = input[2][this.thread.y][this.thread.x];
                var a = input[3][this.thread.y][this.thread.x];
                this.color(r, g, b, a);
            })
                .dimensions([width, height])
                .graphical(true);

            // This is our output canvas, so we can render the result
            var renderCanvas = renderTexture.getCanvas();
            document.body.appendChild(renderCanvas);

            function animate() {
                document.querySelector("#fps").innerHTML = fps.getFPS();

                // Input via image
                blitCanvasContext.drawImage(video, 0, 0, width, height);

                // Convert image to array data
                var data = blitCanvasContext.getImageData(0, 0, width, height).data;

                // Convert array to texture
                var texture = importTexture(data, width, height);

                // Apply filters
                texture = filterTexture(texture);

                // Render the texture to screen
                renderTexture(texture);

                // The multi-kernels f-up the canvas dimensions
                renderCanvas.width = width;
                renderCanvas.height = height;

                // Loop when we should animate
                requestAnimationFrame(animate);
            }

            // Request stream from video object
            navigator.mediaDevices.getUserMedia({
                audio: false,
                video: {
                    facingMode: "user"
                }
            }).then(function success(stream) {
                video.srcObject = stream;
                requestAnimationFrame(animate);
            });
        });
    </script>
</body>

</html>
